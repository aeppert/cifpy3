#!/usr/bin/env python3
#
# cif Server - Listens and handles all data incoming/outgoing
#
import argparse
import logging
import multiprocessing
import os
import setproctitle
import signal
import sys
import time

import pika

__author__ = 'James DeVincentis <james.d@hexhost.net>'

# Append our local lib directory to the import paths
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'lib'))

import cif

# Setup Paths for global usage throughout the cif package
cif.BINDIR = os.path.dirname(os.path.abspath(__file__))
cif.APPDIR = os.path.dirname(cif.BINDIR)
cif.LIBDIR = os.path.join(cif.APPDIR, 'lib')
cif.ETCDIR = os.path.join(cif.APPDIR, 'etc')
cif.LOGDIR = os.path.join(cif.APPDIR, 'log')
cif.CACHEDIR = os.path.join(cif.APPDIR, 'cache')

parser = argparse.ArgumentParser(description='Collective Intelligence Framework Server',
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--logfile', dest='logfile', nargs='?', default=os.path.join(cif.LOGDIR, 'cif-server.log'))
parser.add_argument('--loglevel', dest='loglevel', nargs='?', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                    default='WARNING')

group = parser.add_argument_group(title='Worker Options', description='Customize Worker behavior')
group.add_argument('--worker-disable', dest='worker_disable', action="store_true", help='disable workers')
group.add_argument('--worker-start', dest='workers_start', nargs='?', type=int, default=1,
                   help='number of workers to spawn at start')
group.add_argument('--workers-max', dest='workers_max', nargs='?', type=int, default=multiprocessing.cpu_count(),
                   help='maximum number of workers to during heavy load')
group.add_argument('--worker-threads-start', dest='worker_threads_start', nargs='?', type=int, default=5,
                   help='number of threads per worker to spawn at start')
group.add_argument('--worker-threads-max', dest='worker_threads_max', nargs='?', type=int, default=30,
                   help='maximum number of threads per worker during heavy load')

group = parser.add_argument_group('AMQP Settings', description='AMQP 0-9-1 Host Protocol Settings')
group.add_argument('--mq-host', dest='mq_host', nargs='?', default='127.0.0.1',
                   help='host server IP')
group.add_argument('--mq-port', dest='mq_port', nargs='?', type=int, default=5672, help='host server Port')
group.add_argument('--mq-work-queue-name', dest='mq_work_queue_name', nargs='?', default='cifpy3_worker_queue',
                   help='RabbitMQ Worker Queue Name')
group.add_argument('--mq-observable-exchange-name', dest='mq_observable_exchange_name', nargs='?',
                   default='cifpy3_observables', help='RabbitMQ Observables Exchange Name')

group = parser.add_argument_group('API Options', description='API Server behavior')
group.add_argument('--api-disable', dest='api_disable', action="store_true", help='disable API')
group.add_argument('--api-address', dest='host', nargs='?', type=str, default='0.0.0.0',
                   help='Host to listen on')
group.add_argument('--api-port', dest='port', nargs='?', type=int, default=8080, help='Port to listen on')
group.add_argument('--api-disable-auth', dest='noauth', action="store_true",
                   help='disable authentication (insecure: not recommended)')
group.add_argument('--api-handler-max-count', dest='handler_max_count', nargs='?', type=int, default=4000,
                   help='maximum number of observables returend by the backend')

group = parser.add_argument_group('Storage Options')
group.add_argument('--storage-engine', dest='storage', nargs='?', type=str, default='elasticsearch',
                   help='storage engine')
group.add_argument('--storage-connection', dest='storage_uri', nargs='?', type=str,
                   default='http://127.0.0.1:9200', help='Connection string for connecting to the storage engine')

group = parser.add_argument_group('Feeder Options')
group.add_argument('--feeder-disable', dest='feed_disable', action="store_true", help='Disable Feeder program')
group.add_argument('--feeder-directory', dest='feed_directory', nargs='?', type=str,
                   default=os.path.join(cif.ETCDIR, 'feeds'), help='Read feed configurations from this directory')
group.add_argument('--feeder-http-proxy', dest='feed_http_proxy', nargs='?', type=str,
                   help='HTTP Proxy for accessing feeds')
group.add_argument('--feeder-https-proxy', dest='feed_https_proxy', nargs='?', type=str,
                   help='HTTPS Proxy for accessing feeds')

# Notifications are not yet supported
# group = parser.add_argument_group('Notification Options')
# group.add_argument('--notify', action="store_true", help='enable notification')
# group.add_argument('--notify-to', dest='notify_to', nargs='?', type=str, default='root',
#                    help='notification recipient')
# group.add_argument('--notify-from', dest='notify_from', nargs='?', type=str, default='cif', help='from address')
# group.add_argument('--notify-prefix', dest='notify_prefix', nargs='?', type=str, default='[cif Server]',
#                   help='notification subject prefix')
# group.add_argument('--notify-level', dest='notify_level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
#                   default='ERROR', help='level to notify at')


# Assign options for global usage in the cif package
cif.options = parser.parse_args()

# Configure our basic logging.
logging.basicConfig(level=getattr(logging, cif.options.loglevel),
                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S', filename=cif.options.logfile, filemode='a'
                    )

cif.logging = logging
logger = cif.logging.getLogger("MAIN")

# Set up proxies
if "feed_http_proxy" in cif.options:
    logger.debug("HTTP Proxy Set to: {0}".format(cif.options.feed_http_proxy))
    cif.proxies["http"] = cif.options.feed_http_proxy

if "feed_https_proxy" in cif.options:
    logger.debug("HTTPS Proxy Set to: {0}".format(cif.options.feed_https_proxy))
    cif.proxies["https"] = cif.options.feed_https_proxy

if not os.path.exists(cif.options.feed_directory):
    logger.fatal("Feed Config Directory ({0}) does not exist.".format(cif.options.feed_directory))
    sys.exit(1)

api = None
feeder = None
workers = {}


# Hook into SIGINT
def sigint_handler(signum, frame):
    logger.warning("Received Signal #{0}. Exiting.".format(signum))
    # noinspection PyBroadException
    try:
        if not cif.options.worker_disable:
            logger.info("Killing Workers")
            for worker in range(1, cif.options.workers_start + 1):
                worker.stop()
        if not cif.options.api_disable:
            logger.info("Killing api")
            api.terminate()
        if not cif.options.feed_disable:
            logger.info("Killing feeder")
            feeder.terminate()
    except:
        pass
    del frame
    sys.exit(0)


signal.signal(signal.SIGINT, sigint_handler)

try:
    setproctitle.setproctitle('CIF-SERVER (Controller)')
except:
    pass

logger.info("Setting up RabbitMQ Queues")
connection = pika.BlockingConnection(pika.ConnectionParameters(host=cif.options.mq_host, port=cif.options.mq_port))
channel = connection.channel()
channel.queue_declare(queue=cif.options.mq_work_queue_name, durable=True)
channel.exchange_declare(exchange=cif.options.mq_observable_exchange_name, type='fanout')
pika_logger = logging.getLogger('pika')
pika_logger.setLevel(logging.ERROR)

logger.info("Monitoring Loop: Entering")

# If someone is dopey enough to do this...
if cif.options.worker_disable and cif.options.api_disable and cif.options.feed_disable:
    logger.error("Workers, API, and Feeder are disabled, exiting. https://youtu.be/m4OvQIGDg4I ")
    sys.exit(0)

while True:
    if not cif.options.worker_disable:
        logger.info("Monitoring Loop: Checking Workers")
        for i in range(1, cif.options.workers_start + 1):
            logger.info("Monitoring Loop: Checking worker {0}".format(i))
            if i not in workers or workers[i] is None or not workers[i].is_alive():
                if i in workers and workers[i] is not None and not workers[i].recycle:
                    logger.error("Monitoring Loop: worker #{0} died or not started. Restarting.".format(i))
                if i in workers and workers[i] is not None and workers[i].recycle:
                    workers[i].join()
                workers[i] = cif.worker.Process(str(i))
                workers[i].daemon = 1
                workers[i].start()

    if not cif.options.api_disable:
        cif.logging.info("Monitoring Loop: Checking api Server")
        if api is None or not api.is_alive():
            if api is not None:
                logger.error("Monitoring Loop: api Server Died. Restarting.")
            api = cif.api.Server()
            api.daemon = 1
            api.start()

    if not cif.options.feed_disable:
        cif.logging.info("Monitoring Loop: Checking feeder")
        if feeder is None or not feeder.is_alive():
            if feeder is not None:
                logger.error("Monitoring Loop: feeder died. Restarting.")
            feeder = cif.feeder.Feeder()
            feeder.start()

    logger.debug("Monitoring Loop: Sleeping")

    time.sleep(5)
