#!/usr/bin/env python3
#
# cif Utility - Installs/Uninstalls & Clears the storage engine
#
__author__ = 'James DeVincentis <james.d@hexhost.net>'

import os
import sys
import datetime
import argparse
import logging
import gzip
import shutil
import re

import requests

# Append our local lib directory to the import paths
sys.path.append("{0}/lib".format(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import cif

# Setup Paths for global usage throughout the cif package
cif.BINDIR = os.path.dirname(os.path.abspath(__file__))
cif.APPDIR = os.path.dirname(cif.BINDIR)
cif.LIBDIR = "{0}/lib".format(cif.APPDIR)
cif.ETCDIR = "{0}/etc".format(cif.APPDIR)
cif.LOGDIR = "{0}/log".format(cif.APPDIR)
cif.CACHEDIR = "{0}/cache".format(cif.APPDIR)

parser = argparse.ArgumentParser(description='Collective Intelligence Framework Utility',
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
commands = parser.add_mutually_exclusive_group(required=True)
commands.add_argument('--install', dest='install', action="store_true",
                      help='Install tables to backend storage engine')
commands.add_argument('--uninstall', dest='uninstall', action="store_true",
                      help='Install tables to backend storage engine')
commands.add_argument('--reinstall', dest='reinstall', action="store_true",
                      help='Install tables to backend storage engine')
commands.add_argument('--delete', dest='clear', action="store_true",
                      help='Delete all observables')
commands.add_argument('--geoip', dest='geoip', action="store_true",
                      help='Download GeoIP Data into LIB directory')
commands.add_argument('--clean', dest='clean', action="store_true",
                      help='Remove observables older than --days number of days')

parser.add_argument('--clean-days', dest='days', nargs='?', type=int, default=14,
                    help='Number of days to remove')
parser.add_argument('--verbose', dest='loglevel', nargs='?', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                    default='WARNING')

group = parser.add_argument_group('Storage Options')
group.add_argument('--storage-engine', dest='storage', nargs='?', type=str, default='elasticsearch',
                   help='storage engine')
group.add_argument('--storage-connection', dest='storage_uri', nargs='?', type=str,
                   default='http://127.0.0.1:9200', help='Connection string for connecting to the storage engine')

# Assign options for global usage in the cif package
cif.options = parser.parse_args()

# Configure our basic logging.
logging.basicConfig(level=getattr(logging, cif.options.loglevel),
                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                    )

cif.logging = logging
logger = cif.logging.getLogger("UTILITY")

# Start Server to handle incoming connections
if __name__ == "__main__":
    if "geoip" in cif.options and cif.options.geoip:
        response = requests.get("http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz", stream=True)
        if response.status_code > 300:
            raise Exception("Got error code from fetching feed: {0} {1}".format(response.status_code, response.reason))

        geo_path_gz = os.path.join(cif.LIBDIR, "GeoIP", "GeoLiteCity.dat.gz")
        geo_path = os.path.join(cif.LIBDIR, "GeoIP", "GeoLiteCity.dat")
        # Start a temporary file to write to
        temp = open(geo_path_gz, "wb")

        # Store 1MB at a time
        for chunk in response.iter_content(1024 * 1024):
            temp.write(chunk)

        # Close the response
        response.close()
        temp.close()

        with open(geo_path, 'wb') as f_out, gzip.open(geo_path_gz, 'rb') as f_in:
            shutil.copyfileobj(f_in, f_out)
        os.unlink(geo_path_gz)
        print("Downloaded GEOIP Data")
        sys.exit(0)

    backend = __import__("cif.backends.{0:s}".format(cif.options.storage.lower()),
                         fromlist=[cif.options.storage.title()])

    backend = getattr(backend, cif.options.storage.title())()

    backend.connect(cif.options.storage_uri)

    if "install" in cif.options and cif.options.install:
        backend.install()

        # Create a default token for the admin user
        token = cif.types.Token({
            "write": 1,
            "admin": 1,
            "username": "admin",
            "description": 'Default admin token created on installation'
        })
        backend.token_create(token)
        print("token: {0}".format(token.token))

    if "reinstall" in cif.options and cif.options.reinstall:
        backend.uninstall()
        backend.install()

        # Create a default token for the admin user
        token = cif.types.Token({
            "write": 1,
            "admin": 1,
            "username": "admin",
            "description": 'Default admin token created on installation'})
        backend.token_create(token)
        print("token: {0}".format(token.token))

    if "uninstall" in cif.options and cif.options.uninstall:
        backend.uninstall()

    if "clear" in cif.options and cif.options.clear:
        backend.clear()

    if "clean" in cif.options and cif.options.clean:
        date = re.compile('(?P<year>[0-9]{4})-(?P<month>[0-9]{2})-(?P<day>[0-9]{2})-journal.pickle$')
        backend.observable_clean(datetime.datetime.now() - datetime.timedelta(days=cif.options.days))
        files = os.listdir(cif.CACHEDIR)
        for file in files:
            match = date.search(file)
            if match:
                matchdict = match.groupdict()
                date = datetime.datetime(int(matchdict['year']), int(matchdict['month']), int(matchdict['day']))
                if date < (datetime.datetime.now() - datetime.timedelta(days=cif.options.days)):
                    os.unlink(os.path.join(cif.CACHEDIR, file))
